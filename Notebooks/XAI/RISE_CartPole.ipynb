{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Image Sampling for Explanations (RISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize as resize1\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import gym\n",
    "import tensorforce\n",
    "from tensorforce import Agent, Environment\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar agente y definición de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.load(directory='DQNVisionCartPolemodel3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "class CartPoleVisionEnvironment(Environment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.init_screen = self.get_screen()\n",
    "        self.init_state = (self.get_screen() - self.init_screen).cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "        self.last_screen = self.init_screen\n",
    "        self.current_screen = self.init_screen\n",
    "        super().__init__()\n",
    "        \n",
    "    def get_cart_location(self, screen_width):\n",
    "        world_width = self.env.x_threshold * 2\n",
    "        scale = screen_width / world_width\n",
    "        return int(self.env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "        \n",
    "    def get_screen(self):\n",
    "        # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "        # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "        screen = self.env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "        # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "        _, screen_height, screen_width = screen.shape\n",
    "        screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "        view_width = int(screen_width * 0.6)\n",
    "        cart_location = self.get_cart_location(screen_width)\n",
    "        if cart_location < view_width // 2:\n",
    "            slice_range = slice(view_width)\n",
    "        elif cart_location > (screen_width - view_width // 2):\n",
    "            slice_range = slice(-view_width, None)\n",
    "        else:\n",
    "            slice_range = slice(cart_location - view_width // 2,\n",
    "                                cart_location + view_width // 2)\n",
    "        # Strip off the edges, so that we have a square image centered on a cart\n",
    "        screen = screen[:, :, slice_range]\n",
    "        # Convert to float, rescale, convert to torch tensor\n",
    "        # (this doesn't require a copy)\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        # Resize, and add a batch dimension (BCHW)\n",
    "        return resize(screen).unsqueeze(0)\n",
    "    \n",
    "    def is_vectorizable(self):\n",
    "        return True                          \n",
    "    \n",
    "    def actions(self):\n",
    "        return dict(type='int', shape=(), num_values=2)\n",
    "\n",
    "    def states(self):\n",
    "        return dict(type='float', shape=self.init_state.shape)\n",
    "\n",
    "    def execute(self, actions):\n",
    "        _, reward, done, _ = self.env.step(actions)\n",
    "        self.last_screen = self.current_screen\n",
    "        self.current_screen = self.get_screen()\n",
    "        if not done:\n",
    "            next_state = (self.current_screen - self.last_screen).cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "        else: next_state = None\n",
    "        return next_state, done, reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.last_screen = self.init_screen\n",
    "        self.current_screen = self.init_screen\n",
    "        return self.init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos específicos RISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masks(N, s, p1, dimx = 40, dimy = 90):\n",
    "    cell_size = np.ceil(np.array((dimx,dimy)) / s) # si dividimos en s \"cachos\" dim entera\n",
    "    up_size = (s + 1) * cell_size # si cupiese uno mas dim\n",
    "    \n",
    "    grid = np.random.rand(N, s, s) < p1 #generar cuadrado s * s con 0 o 1\n",
    "    grid = grid.astype('float32')\n",
    "    masks = np.empty((N, dimx,dimy)) #lo rellenaremos\n",
    "\n",
    "    for i in tqdm(range(N), desc='Generating masks'):\n",
    "        # Random shifts\n",
    "        x = np.random.randint(0, cell_size[0]) #cuando shift en x\n",
    "        y = np.random.randint(0, cell_size[1]) #cuanto shift en y\n",
    "        # Linear upsampling and cropping\n",
    "        masks[i, :, :] = resize1(grid[i], up_size, order=1, mode='reflect',\n",
    "                                anti_aliasing=False)[x:x + dimx, y:y + dimy]\n",
    "        \n",
    "    masks = masks.reshape(-1, dimx,dimy , 1)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(inp, masks , agent, dimx = 40, dimy = 90):\n",
    "    preds = []\n",
    "    # Make sure multiplication is being done for correct axes\n",
    "    masked = inp * masks\n",
    "    \n",
    "    #print(masked.shape) # = (2000, 40, 90, 3) => N alteraciones de la imagen x \n",
    "    for i in tqdm(range (0,N), desc = 'Explaining'):\n",
    "        decision = agent.act(states=masked[i], independent = True, deterministic=True)\n",
    "        elem = agent.tracked_tensors()['agent/policy/action-values']\n",
    "        softmax = tf.nn.softmax(elem).numpy()\n",
    "        preds.append(softmax)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    \n",
    "\n",
    "    sal = preds.T.dot(masks.reshape(N, -1)).reshape(-1, dimx,dimy)\n",
    "    sal = sal / N / p1\n",
    "    return sal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency(class_idx,img, sal):\n",
    "    plt.title('Explanation for `{}`'.format(act_dict[class_idx]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(sal[class_idx], cmap='jet', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la explicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "act_dict = {0:'LEFT',1:'RIGHT'}\n",
    "environment =  Environment.create(environment = CartPoleVisionEnvironment, max_episode_timesteps=10000)\n",
    "states = environment.reset()\n",
    "terminal = False\n",
    "#constantes generacion mascaras\n",
    "N = 4000\n",
    "s = 8\n",
    "p1 = 0.5\n",
    "masks = generate_masks(N, s, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while(not terminal):\n",
    "    screen = environment.get_screen()\n",
    "    transform = T.ToPILImage()\n",
    "    img = transform(screen[0])\n",
    "    actions = agent.act(states=states, independent = True, deterministic=True)\n",
    "    if i % 5 == 0:\n",
    "        sal = explain(states, masks , agent)\n",
    "        saliency(actions,img,sal)\n",
    "    states, terminal, reward = environment.execute(actions=actions)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
